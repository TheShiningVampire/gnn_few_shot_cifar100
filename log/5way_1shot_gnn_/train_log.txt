todo             : train
dataset          : cifar100
model_type       : gnn
pretrain         : False
pretrain_dir     : 
use_gpu          : 0
seed             : 1
batch_size       : 16
lr               : 0.01
max_iteration    : 100000
log_interval     : 100
eval_interval    : 2000
early_stop       : 5
early_stop_pretrain : 5
test_dir         : 
data_root        : data
log_root         : log
model_root       : model
affix            : 
save             : False
load             : False
load_dir         : 
output_dir       : output
output_name      : output.txt
nway             : 5
shots            : 1
freeze_cnn       : False
model_folder     : model\5way_1shot_gnn_
log_folder       : log\5way_1shot_gnn_
gnnModel(
  (cnn_feature): EmbeddingCNN(
    (module_list): ModuleList(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (3): LeakyReLU(negative_slope=0.1, inplace=True)
      (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (7): LeakyReLU(negative_slope=0.1, inplace=True)
      (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (11): LeakyReLU(negative_slope=0.1, inplace=True)
      (12): Conv2d(128, 64, kernel_size=(4, 4), stride=(1, 1), bias=False)
      (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (14): LeakyReLU(negative_slope=0.1, inplace=True)
    )
  )
  (gnn): GNN(
    (gnn_obj): GNN_module(
      (adjacency_list): ModuleList(
        (0): Adjacency_layer(
          (module_list): ModuleList(
            (0): Conv2d(69, 64, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): LeakyReLU(negative_slope=0.01)
            (3): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): LeakyReLU(negative_slope=0.01)
            (6): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (1): Adjacency_layer(
          (module_list): ModuleList(
            (0): Conv2d(85, 64, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): LeakyReLU(negative_slope=0.01)
            (3): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (5): LeakyReLU(negative_slope=0.01)
            (6): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
          )
        )
      )
      (graph_conv_list): ModuleList(
        (0): Graph_conv_block(
          (weight): Linear(in_features=69, out_features=16, bias=True)
          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Graph_conv_block(
          (weight): Linear(in_features=85, out_features=16, bias=True)
          (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (last_adjacency): Adjacency_layer(
        (module_list): ModuleList(
          (0): Conv2d(101, 64, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.01)
          (3): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))
          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): LeakyReLU(negative_slope=0.01)
          (6): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
        )
      )
      (last_conv): Graph_conv_block(
        (weight): Linear(in_features=101, out_features=5, bias=True)
      )
    )
  )
)
iter: 0, spent: 1.8727 s, tr loss: 1.69601
================== eval ==================
iter: 0, va loss: 2.00482, va acc: 20.5929 %
==========================================
iter: 100, spent: 2.9430 s, tr loss: 1.66566
iter: 200, spent: 3.1990 s, tr loss: 1.63251
iter: 300, spent: 2.8511 s, tr loss: 1.62388
iter: 400, spent: 2.8952 s, tr loss: 1.62010
iter: 500, spent: 2.9518 s, tr loss: 1.61196
iter: 600, spent: 2.9224 s, tr loss: 1.61883
iter: 700, spent: 2.9544 s, tr loss: 1.61530
iter: 800, spent: 2.9126 s, tr loss: 1.61239
iter: 900, spent: 3.1009 s, tr loss: 1.61445
iter: 1000, spent: 2.8134 s, tr loss: 1.61255
iter: 1100, spent: 2.9013 s, tr loss: 1.61386
iter: 1200, spent: 2.8480 s, tr loss: 1.61191
iter: 1300, spent: 2.9179 s, tr loss: 1.60990
iter: 1400, spent: 2.9109 s, tr loss: 1.60489
iter: 1500, spent: 2.8051 s, tr loss: 1.61385
iter: 1600, spent: 2.8655 s, tr loss: 1.60424
iter: 1700, spent: 2.9014 s, tr loss: 1.60843
iter: 1800, spent: 2.9295 s, tr loss: 1.59346
iter: 1900, spent: 3.1154 s, tr loss: 1.58918
iter: 2000, spent: 2.8930 s, tr loss: 1.58133
================== eval ==================
iter: 2000, va loss: 1.58000, va acc: 26.3421 %
==========================================
iter: 2100, spent: 3.0643 s, tr loss: 1.58145
iter: 2200, spent: 2.9888 s, tr loss: 1.56848
iter: 2300, spent: 3.1108 s, tr loss: 1.57140
iter: 2400, spent: 2.9982 s, tr loss: 1.56019
iter: 2500, spent: 3.0061 s, tr loss: 1.56880
iter: 2600, spent: 3.1497 s, tr loss: 1.55824
iter: 2700, spent: 3.2692 s, tr loss: 1.55951
iter: 2800, spent: 2.9006 s, tr loss: 1.54959
iter: 2900, spent: 3.0922 s, tr loss: 1.56829
iter: 3000, spent: 3.0868 s, tr loss: 1.55179
iter: 3100, spent: 2.9437 s, tr loss: 1.54413
iter: 3200, spent: 3.1325 s, tr loss: 1.55283
iter: 3300, spent: 2.9310 s, tr loss: 1.51440
iter: 3400, spent: 3.2622 s, tr loss: 1.54465
iter: 3500, spent: 3.4162 s, tr loss: 1.53515
iter: 3600, spent: 3.6168 s, tr loss: 1.54039
iter: 3700, spent: 3.5778 s, tr loss: 1.51672
iter: 3800, spent: 3.3770 s, tr loss: 1.51902
iter: 3900, spent: 3.3419 s, tr loss: 1.54409
iter: 4000, spent: 3.3196 s, tr loss: 1.51108
================== eval ==================
iter: 4000, va loss: 1.52371, va acc: 33.8141 %
==========================================
iter: 4100, spent: 3.2213 s, tr loss: 1.53497
iter: 4200, spent: 3.4454 s, tr loss: 1.52317
iter: 4300, spent: 3.3948 s, tr loss: 1.52377
iter: 4400, spent: 3.1452 s, tr loss: 1.51758
iter: 4500, spent: 3.2434 s, tr loss: 1.50262
iter: 4600, spent: 3.2160 s, tr loss: 1.50387
iter: 4700, spent: 3.1857 s, tr loss: 1.50862
iter: 4800, spent: 3.4237 s, tr loss: 1.49975
iter: 4900, spent: 3.1086 s, tr loss: 1.49996
iter: 5000, spent: 3.4060 s, tr loss: 1.49721
iter: 5100, spent: 3.3732 s, tr loss: 1.51036
iter: 5200, spent: 3.3265 s, tr loss: 1.49847
iter: 5300, spent: 3.3109 s, tr loss: 1.47158
iter: 5400, spent: 3.1888 s, tr loss: 1.48724
iter: 5500, spent: 3.2894 s, tr loss: 1.46950
iter: 5600, spent: 3.5029 s, tr loss: 1.46056
iter: 5700, spent: 3.2030 s, tr loss: 1.50698
iter: 5800, spent: 3.4461 s, tr loss: 1.48378
iter: 5900, spent: 3.2858 s, tr loss: 1.48306
iter: 6000, spent: 3.3318 s, tr loss: 1.48296
================== eval ==================
iter: 6000, va loss: 1.51552, va acc: 32.5120 %
==========================================
iter: 6100, spent: 3.3865 s, tr loss: 1.49177
iter: 6200, spent: 3.8600 s, tr loss: 1.46259
iter: 6300, spent: 3.9822 s, tr loss: 1.45762
iter: 6400, spent: 3.3821 s, tr loss: 1.48154
